@book{pena2008self,
  title={Self-normalized processes: Limit theory and Statistical Applications},
  author={Pe{\~n}a, Victor H and Lai, Tze Leung and Shao, Qi-Man},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@inproceedings{leurent2019interval,
	author    = {Leurent, E. and Efimov, D. and Ra\"issi, T. and Perruquetti, W.},
	title     = {Interval Prediction for Continuous-Time Systems with Parametric Uncertainties},
	booktitle = {Proc. IEEE Conference on Decision and Control (CDC)},
	year      = {2019},
	address   = {Nice},
}

@article{Efimov2013,
  author = {Efimov, D. and Ra\"issi, T. and Chebotarev, S. and Zolghadri, A.},
  title = {Interval State Observer for Nonlinear Time Varying Systems},
  journal = {Automatica},
  year = {2013},
  volume = {49},
  pages = {200--205},
  number = {1},
  owner = {EfDe},
  timestamp = {2013.01.08}
}

@unpublished{maillard2016,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; self-normalized ; sequential prediction},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v1},
}

@incollection{Abbasi2011,
title = {Improved Algorithms for Linear Stochastic Bandits},
author = {Yasin Abbasi-yadkori and P\'{a}l, D\'{a}vid and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {2312--2320},
year = {2011},
publisher = {Curran Associates, Inc.},
}



@InProceedings{abbasi-yadkori11a,
  title = 	 {Regret Bounds for the Adaptive Control of Linear Quadratic Systems},
  author = 	 {Yasin Abbasi-Yadkori and Csaba Szepesvári},
  booktitle = 	 {Proceedings of the 24th Annual Conference on Learning Theory},
  pages = 	 {1--26},
  year = 	 {2011},
  editor = 	 {Sham M. Kakade and Ulrike von Luxburg},
  volume = 	 {19},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Budapest, Hungary},
  month = 	 {09--11 Jun},
  publisher = 	 {PMLR},
}

@InProceedings{abeille18a,
  title = 	 {Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems},
  author = 	 {Abeille, Marc and Lazaric, Alessandro},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1--9},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  abstract = 	 {Thompson sampling (TS) is an effective approach to trade off exploration and exploration in reinforcement learning. Despite its empirical success and recent advances, its theoretical analysis is often limited to the Bayesian setting, finite state-action spaces, or finite-horizon problems. In this paper, we study an instance of TS in the challenging setting of the infinite-horizon linear quadratic (LQ) control, which models problems with continuous state-action variables, linear dynamics, and quadratic cost. In particular, we analyze the regret in the frequentist sense (i.e., for a fixed unknown environment) in one-dimensional systems. We derive the first $O(\sqrt{T})$ frequentist regret bound for this problem, thus significantly improving the $O(T^{2/3})$ bound of Abeille & Lazaric (2017) and matching the frequentist performance derived by Abbasi-Yadkori & Szepesvári (2011) for an optimistic approach and the Bayesian result Ouyang et al. (2017) We obtain this result by developing a novel bound on the regret due to policy switches, which holds for LQ systems of any dimensionality and it allows updating the parameters and the policy at each step, thus overcoming previous limitations due to lazy updates. Finally, we report numerical simulations supporting the conjecture that our result extends to multi-dimensional systems.}
}

@article{Dean2017,
  title={On the Sample Complexity of the Linear Quadratic Regulator},
  author={Sarah Dean and Horia Mania and Nikolai Matni and Benjamin Recht and Stephen Tu},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.01688}
}

@incollection{Dean2018,
title = {Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator},
author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {4188--4197},
year = {2018},
publisher = {Curran Associates, Inc.},
}


@inproceedings{kirschner18heteroscedastic,
	Author = {Johannes Kirschner and Andreas Krause},
	Booktitle = {Proc. International Conference on Learning Theory (COLT)},
	Month = {July},
	Title = {Information Directed Sampling and Bandits with Heteroscedastic Noise},
	Year = {2018}}
	
@unpublished{maillard:hal-01349727,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; sequential prediction ; self-normalized},
  PDF = {https://hal.archives-ouvertes.fr/hal-01349727/file/HalSubmittedV2.pdf},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v2},
}

@inproceedings{Hren2008,
	title = {{Optimistic planning of deterministic systems}},
	author = {Hren, Jean-Francois and Munos, R{\'e}mi},
	booktitle = {{European Workshop on Reinforcement Learning}},
	address = {France},
	pages = {151-164},
	year = {2008},
	hal_id = {hal-00830182},
	hal_version = {v1},
}

@article{Schneider1997,
author = {Schneider, JG},
journal = {Advances in neural information processing systems},
pages = {1047----1053},
title = {{Exploiting model uncertainty estimates for safe dynamic control learning}},
year = {1997}
}

@article{delos2015,
  TITLE = {{Minkowski Sum of Polytopes Defined by Their Vertices}},
  AUTHOR = {Delos, Vincent and Teissandier, Denis},
  JOURNAL = {{Journal of Applied Mathematics and Physics (JAMP)}},
  VOLUME = {3},
  NUMBER = {1},
  PAGES = {62-67},
  YEAR = {2015},
  MONTH = Jan,
}


@article{Iyengar2005,
	author = {Iyengar, Garud N.},
	journal = {Mathematics of Operations Research},
	pages = {257--280},
	title = {{Robust Dynamic Programming}},
	volume = {30},
	year = {2005}
}

@article{Nilim2005,
	author = {Nilim, Arnab and {El Ghaoui}, Laurent},
	journal = {Operations Research},
	pages = {780--798},
	title = {{Robust Control of Markov Decision Processes with Uncertain Transition Matrices}},
	volume = {53},
	year = {2005}
}

@article{Wiesemann2013,
	author = {Wiesemann, Wolfram and Kuhn, Daniel and Rustem, Ber{\c{c}}},
	journal = {Mathematics of Operations Research},
	mendeley-groups = {Robust Control},
	pages = {1--52},
	title = {{Robust Markov Decision Processes}},
	year = {2013}
}

@misc{highway-env,
	author = {Leurent, Edouard},
	title = {An Environment for Autonomous Driving Decision-Making},
	year = {2018},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/eleurent/highway-env}},
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	publisher = {American Association for the Advancement of Science},
	journal = {Science}
}

@article{mnih2015humanlevel,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	journal = {Nature},
	month = feb,
	number = 7540,
	pages = {529--533},
	publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	title = {Human-level control through deep reinforcement learning},
	volume = 518,
	year = 2015
}

@book{Basar1996,
	author = {Basar, T. and Bernhard, P.},
	booktitle = {IEEE Transactions on Automatic Control},
	pages = {411},
	title = {{H infinity - Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach}},
	volume = {41},
	year = {1996}
}

@inproceedings{busoniu2013,
	author = {Busoniu, Lucian and Daniels, Alexander and Munos, Remi and Babuska, Robert},
	year = {2013},
	month = {04},
	booktitle = {IEEE International Symposium on Adaptive Dynamic Programming and Reinforcement Learning},
	title = {Optimistic Planning for Continuous-Action Deterministic Systems},
}

@inproceedings{Mansley2011,
	author = {Mansley, Chris and Weinstein, Ari and Littman, Michael},
	year = {2011},
	month = {01},
	title = {Sample-Based Planning for Continuous Action Markov Decision Processes.},
	journal = {Proceedings of the 21st International Conference on Automated Planning and Scheduling}
}

@article{Weinstein2012,
	author = {Weinstein, A. and Littman, M.L.},
	year = {2012},
	month = {01},
	pages = {306-314},
	title = {Bandit-based planning and learning in continuous-action markov decision processes},
	journal = {Proceedings of the 22nd International Conference on Automated Planning and Scheduling}
}

@article{Busoniu2018,
	author = {Busoniu, Lucian and Pall, Elod and Munos, Remi},
	year = {2018},
	month = {06},
	pages = {100-108},
	title = {Continuous-action planning for discounted infinite-horizon nonlinear optimal control with Lipschitz values},
	volume = {92},
	journal = {Automatica},
}

@ARTICLE{Efimov2012,
	author = {Efimov, D. and Fridman, L.M. and Ra\"issi, T. and Zolghadri, A. and
	Seydou, R.},
	title = {Interval Estimation for {LPV} Systems Applying High Order Sliding
	Mode Techniques},
	journal = {Automatica},
	year = {2012},
	volume = {48},
	pages = {2365--2371},
}

@article{Kumar2013,
	title = {Robust LQR Controller Design for Stabilizing and Trajectory Tracking of Inverted Pendulum},
	journal = {Procedia Engineering},
	volume = {64},
	pages = {169 - 178},
	year = {2013},
	note = {International Conference on Design and Manufacturing},
	author = {E. Vinodh Kumar and Jovitha Jerome}
}

@inproceedings{Lenz2015,
	title={DeepMPC: Learning Deep Latent Features for Model Predictive Control},
	author={Ian Lenz and Ross A. Knepper and Ashutosh Saxena},
	booktitle={Robotics: Science and Systems},
	year={2015}
}

@article{Levine2015,
	author    = {Sergey Levine and
	Chelsea Finn and
	Trevor Darrell and
	Pieter Abbeel},
	title     = {End-to-End Training of Deep Visuomotor Policies},
	journal   = {CoRR},
	volume    = {abs/1504.00702},
	year      = {2015},
	archivePrefix = {arXiv},
	eprint    = {1504.00702}
}

@book{Bental2009,
	title={Robust optimization},
	author={Ben-Tal, Aharon and El Ghaoui, Laurent and Nemirovski, Arkadi},
	volume={28},
	year={2009},
	publisher={Princeton University Press}
}
@article{Bertsimas2011,
	title={Theory and applications of robust optimization},
	author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
	journal={SIAM review},
	volume={53},
	number={3},
	pages={464--501},
	year={2011},
	publisher={SIAM}
}

@article{Gorissen2015,
	title = {A practical guide to robust optimization},
	journal = {Omega},
	volume = {53},
	pages = {124 - 137},
	year = {2015},
	author = {Bram L. Gorissen and İhsan Yanıkoğlu and Dick den Hertog},
}

@phdthesis{le2012,
	TITLE = {Robust predictive control by zonotopic set-membership estimation.},
	AUTHOR = {Le, Vu Tuan Hieu},
	NUMBER = {2012SUPL0016},
	SCHOOL = {{Sup{\'e}lec}},
	YEAR = {2012},
	MONTH = Oct,
	KEYWORDS = {Uncertain system ; Model predictive control ; Set-membership estimation ; Syst{\`e}me incertain ; Estimation ensembliste ; Zonotope ; Commande pr{\'e}dictive},
	TYPE = {Theses}
}

@article{Ibrahimi2013,
	author = {Ibrahimi, Morteza and Javanmard, Adel and Roy, Benjamin},
	year = {2013},
	month = {03},
	title = {Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems},
	volume = {4},
	journal = {Advances in Neural Information Processing Systems}
}

@article{Faradonbeh2017,
	author    = {Mohamad Kazem Shirani Faradonbeh and Ambuj Tewari and George Michailidis},
	title     = {Finite Time Analysis of Optimal Adaptive Policies for Linear-Quadratic
	Systems},
	journal   = {CoRR},
	volume    = {abs/1711.07230},
	year      = {2017},
	archivePrefix = {arXiv},
	eprint    = {1711.07230},
}

@article{Ouyang2017,
	author    = {Yi Ouyang and
	Mukul Gagrani and
	Rahul Jain},
	title     = {Learning-based Control of Unknown Linear Systems with Thompson Sampling},
	journal   = {CoRR},
	volume    = {abs/1709.04047},
	year      = {2017},
	archivePrefix = {arXiv},
	eprint    = {1709.04047},
}